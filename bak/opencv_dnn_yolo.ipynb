{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import os, sys, joblib, glob, shutil, json, time, datetime\n",
    "import cv2\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import darknet\n",
    "import requests\n",
    "from collections import Counter\n",
    "import threading, multiprocessing\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "import imageio, gc\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus)>0:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1000)])\n",
    "#         tf.config.experimental.set_memory_growth(gpus[0], True) \n",
    "#         tf.config.experimental.set_memory_growth(gpus[1], True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print('No GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkFolderExist(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "def getPreviewUrl(cameraName):\n",
    "    url = 'http://localhost:8081/v1/api/ipcamera/previewurl/name'\n",
    "#     url = 'http://10.142.3.61:8081/v1/api/ipcamera/previewurl/name'\n",
    "#    url = 'http://10.109.6.148:8081/v1/api/ipcamera/replayurl/name'     \n",
    "    data = {\n",
    "        \"cameraName\":cameraName,\n",
    "        \"expand\":\"streamform=rtp\" ,\n",
    "        #\"transcode=1&resolution=D1&bitrate=512&framerate=15&streamform=rtp&snapshot=1\"\n",
    "    }\n",
    "    data_json = json.dumps(data)\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "\n",
    "    response = requests.post(url, data=data_json, headers=headers)\n",
    "    jsonObject = response.json()\n",
    "    replayUrl = \"\"\n",
    "    if jsonObject['code'] == '200':\n",
    "        replayUrl = jsonObject['result']['replayUrl']\n",
    "    #print(replayUrl)\n",
    "    print(jsonObject)\n",
    "    return replayUrl\n",
    "\n",
    "\n",
    "def getReplayUrl(cameraName, t1_str, t2_str):\n",
    "    url = 'http://localhost:8081/v1/api/ipcamera/replayurl/name'\n",
    "    data = {\n",
    "        \"cameraName\":cameraName, \n",
    "        \"beginTime\":t1_str, \n",
    "        \"endTime\":t2_str,\n",
    "        \"expand\":\"streamform=rtp\",        \n",
    "#        \"expand\":\"transcode=1&resolution=D1&bitrate=1024&framerate=15&streamform=rtp\"\n",
    "    }\n",
    "    #print(f'{cameraName}: {t1_str} ~ {t2_str}')\n",
    "    data_json = json.dumps(data)\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "\n",
    "    response = requests.post(url, data=data_json, headers=headers)\n",
    "    jsonObject = response.json()\n",
    "    print(jsonObject)\n",
    "    replayUrl = \"\"\n",
    "    if jsonObject['code'] == '200':\n",
    "        replayUrl = jsonObject['result']['replayUrl']\n",
    "    print(replayUrl)\n",
    "    return replayUrl\n",
    "\n",
    "def checkImageNone(fid1, cameraName, cap):\n",
    "    print('last none fid:', fid1, datetime.datetime.today())\n",
    "    time.sleep(60)\n",
    "    replayUrl = getPreviewUrl(cameraName)\n",
    "    cap = cv2.VideoCapture(replayUrl)\n",
    "    ret, image = cap.read()\n",
    "    return ret, image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = 'model/yolov4-tiny-f45-0507_best.weights'#模型权重文件\n",
    "cfg_path = 'cfg/yolov4-tiny-f45-0331.cfg'#模型配置文件\n",
    "labels_path = 'cfg/f45_obj.names'#模型类别标签文件\n",
    "\n",
    "# class: color\n",
    "classid_dict = {0: ['battery_p',(127,255,50)],\n",
    "                1: ['battery_f',(147,20,255)],\n",
    "                2: ['battery',(135,138,128)],\n",
    "                3: ['vpen',(153, 255,255)],\n",
    "                4: ['wz',(221,160,221)],\n",
    "                5: ['ppen',(255,255,86)]}\n",
    "\n",
    "def yolo_dnn(image):\n",
    "    (H,W) = image.shape[: 2]    \n",
    "    # construct a blob from the input frame and then perform a forward\n",
    "    # pass of the YOLO object detector, giving us our bounding boxes\n",
    "    # and associated probabilities\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layerOutputs = net.forward(ln)  \n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "    for output in layerOutputs:  # loop over each of the layer outputs\n",
    "        for detection in output:  # loop over each of the detections\n",
    "            # extract the class ID and confidence (i.e., probability) of the current object detection\n",
    "            scores=detection[5:]  #detection=[x,y,h,w,c,class1,class2] scores取第6位至最后\n",
    "            classID = np.argmax(scores)#np.argmax反馈最大值的索引\n",
    "            confidence = scores[classID]\n",
    "            if confidence >0.2: # filter out weak predictions by ensuring the detected probability is greater than the minimum probability\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height)= box.astype(\"int\")\n",
    "                # left-up corner\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                # update\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "    idxs=cv2.dnn.NMSBoxes(boxes, confidences, 0.2, 0.3)\n",
    "    detections = []\n",
    "    if len(idxs)>0:\n",
    "        box_seq = idxs.flatten()    \n",
    "        for seq in box_seq:\n",
    "            detections.append([classIDs[seq], round(confidences[seq],2), boxes[seq]])\n",
    "    return detections\n",
    "\n",
    "def yolo_bat(image, detections, bat_score):\n",
    "    bat_img = None\n",
    "    f_score = 0\n",
    "    battery_p = list(filter(lambda x: x[0]==0, detections))  #battery_p\n",
    "    if len(battery_p) > 0:\n",
    "        return bat_img, f_score\n",
    "    battery_f = list(filter(lambda x: x[0]==1, detections))  #battery_f\n",
    "    battery_f = sorted(battery_f, key = lambda x: float(x[1]), reverse=True)\n",
    "    battery_f = list(filter(lambda x: float(x[1])>=bat_score, battery_f))\n",
    "    if len(battery_f) > 0:\n",
    "        f_score = float(battery_f[0][1])\n",
    "        x, y, w, h = int(battery_f[0][2][0]), int(battery_f[0][2][1]), int(battery_f[0][2][2]), int(battery_f[0][2][3])\n",
    "        bat_img = cv2.resize(image[y:y+h, x:x+w], (64,64))\n",
    "    return bat_img, f_score\n",
    "\n",
    "def draw_bbox(image, detections):\n",
    "    for detection in detections:\n",
    "        #r_w, r_h = (image.shape[1]/net_wh[0], image.shape[0]/net_wh[1])\n",
    "        x, y, w, h = int(detection[2][0]), int(detection[2][1]), int(detection[2][2]), int(detection[2][3])\n",
    "#         x=x*r_w\n",
    "#         w=w*r_w\n",
    "#         y=y*r_h\n",
    "#         h=h*r_h\n",
    "        x1 = int(round(x - (w / 2)))\n",
    "        y1 = int(round(y - (h / 2)))\n",
    "        x2 = int(round(x + (w / 2)))\n",
    "        y2 = int(round(y + (h / 2))) \n",
    "        #原始的中心點\n",
    "        cx, cy = (x1+x2)//2, (y1+y2)//2\n",
    "        x1 = np.clip(x1, 0, image.shape[1])\n",
    "        y1 = np.clip(y1, 0, image.shape[0])\n",
    "        x2 = np.clip(x2, 0, image.shape[1])\n",
    "        y2 = np.clip(y2, 0, image.shape[0])\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), classid_dict[detection[0]][1], 1)\n",
    "        idx = detections.index(detection)\n",
    "        cv2.putText(image, classid_dict[detection[0]][0]+','+str(detection[1]), (10,130+30*idx) , cv2.FONT_HERSHEY_DUPLEX, 0.6, (255,255,128),1)\n",
    "    cv2.putText(image, f'FID:{fid}', (10,550), cv2.FONT_HERSHEY_DUPLEX,0.7, (255,255,128), 1)\n",
    "    return image\n",
    "\n",
    "\n",
    "#初始化一些参数\n",
    "LABELS = open(labels_path).read().strip().split(\"\\n\")\n",
    "\n",
    "#load YOLO object detector trained\n",
    "net = cv2.dnn.readNetFromDarknet(cfg_path, weights_path)\n",
    "\n",
    "#set CUDA as the preferable backend and target\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "#determine only the *output* layer names that we need from YOLO\n",
    "ln = net.getLayerNames()\n",
    "out = net.getUnconnectedOutLayers() \n",
    "x = []\n",
    "for i in out:   \n",
    "    x.append(ln[i[0]-1])    # i[0]-1    取out中的数字  [200][0]=200  ln(199)= 'yolo_82'\n",
    "ln=x\n",
    "# ln  =  ['yolo_82', 'yolo_94', 'yolo_106']  得到 YOLO需要的输出层\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAskRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  64\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  64\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [64 64  3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           battery\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (2, 4, 8, 16, 32)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  False\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /mnt/hdd/IP_Camera_Installation/ipcamera-env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Loading weights from  model/maskrcnn_0505v2_best.h5\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "class BatteryConfig(Config):\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"battery\"\n",
    "    \n",
    "    NUM_CLASSES = 1 + 3\n",
    "\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    IMAGE_MIN_DIM = 64\n",
    "    IMAGE_MAX_DIM = 64\n",
    "    USE_MINI_MASK = False\n",
    "    RPN_ANCHOR_SCALES = (2, 4, 8, 16, 32)\n",
    "\n",
    "#config = BatteryConfig()\n",
    "#config.display()\n",
    "\n",
    "class InferenceConfig(BatteryConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    USE_MINI_MASK = False\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "inference_config.display()\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"\")\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"model\")\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "mask_model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                           model_dir='model')\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = 'model/maskrcnn_0505v2_best.h5'\n",
    "#model_path = 'model/maskrcnn_best.h5'\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "mask_model.load_weights(model_path, by_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classID: [class name, color]\n",
    "classid_mask = {0: ['BG',(255,255,255)],\n",
    "                1: ['battery',(135,138,128)],\n",
    "                2: ['vpen',(153, 255,255)],\n",
    "                3: ['black',(0,0,0)]}\n",
    "\n",
    "# functions\n",
    "def draw_mask(image, boxes, masks, class_ids, score):\n",
    "\n",
    "    N = boxes.shape[0]\n",
    "    if not N:\n",
    "        print(\"\\n*** No instances to display *** \\n\")\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
    "\n",
    "    masked_image = image.astype(np.uint32).copy()\n",
    "    for i in range(N):\n",
    "        class_id = class_ids[i]\n",
    "        color = classid_mask[class_id][1]\n",
    "        # Bounding box\n",
    "        if not np.any(boxes[i]):\n",
    "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
    "            continue\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        # Mask\n",
    "        mask = masks[:, :, i]\n",
    "        masked_image = apply_mask(masked_image, mask, color)\n",
    "    mergeimg = np.hstack((image, masked_image))\n",
    "    return mergeimg\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == 1,\n",
    "                                  image[:, :, c] * (1 - alpha) + alpha * color[c] * 1,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "\n",
    "def draw_maskscore(image, r, d):\n",
    "    a = dict(zip(r['class_ids'], r['scores']))\n",
    "    alist = [(classid_mask[key][0], int(a[key]*100)) for key in a.keys()] \n",
    "    for value in alist:\n",
    "        idx = alist.index(value)\n",
    "        cv2.putText(image, str(value), (10,300+30*idx) , cv2.FONT_HERSHEY_DUPLEX, 0.6, (221,160,221),1)\n",
    "    dlist = [(key, d[key]) for key in d.keys()] \n",
    "    for value in dlist:\n",
    "        idx = dlist.index(value)\n",
    "        cv2.putText(image, str(str(value).split(',')[:-1]), (10,400+30*idx) , cv2.FONT_HERSHEY_DUPLEX, 0.6, (221,160,221),1)\n",
    "    return image\n",
    "\n",
    "def mask_feature(mask):\n",
    "    contours, _ = cv2.findContours(mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key = cv2.contourArea, reverse=True)\n",
    "    if len(contours) == 0:\n",
    "        return 0,0,0\n",
    "    area = cv2.contourArea(contours[0])\n",
    "    if area == 0:\n",
    "        return 0,0,0\n",
    "    M = cv2.moments(contours[0])\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    return cX, cY, area\n",
    "\n",
    "def get_dist(loc1, loc2):\n",
    "    dist = np.sqrt( (loc1[0] - loc2[0])**2 + (loc1[1] - loc2[1])**2 )\n",
    "    return np.round(dist,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F45_5L2\n",
      "{'message': None, 'code': '200', 'result': {'replayUrl': 'rtsp://10.142.81.21:554/openUrl/2fCvCyA', 'beginTime': None, 'endTime': None, 'size': None, 'message': 'success'}}\n"
     ]
    }
   ],
   "source": [
    "### API\n",
    "mid = 'F45_5L2'\n",
    "fps = 15\n",
    "camera_df = pd.read_excel(f'doc/camera_list_map.xlsx')\n",
    "camera_name = camera_df[camera_df['mid']==mid]['camera_name'].values[0]\n",
    "ip = camera_df[camera_df['mid']==mid]['ip'].values[0]\n",
    "line = camera_df[camera_df['mid']==mid]['mes_line'].values[0]\n",
    "station = camera_df[camera_df['mid']==mid]['mes_station'].values[0]\n",
    "print(mid) \n",
    "\n",
    "### Local files\n",
    "# vpath = '/mnt/hdd1/f45_dev/FA_5L2_video/F45_5L2_2021-05-17T17:51:46.000+08:00_G99FPQHKQ123.mp4'\n",
    "# vname = vpath.split('/')[-1].split('_')[-2]\n",
    "# #vpath = 'output/1216/F68_5L2_replay_1608101363.1398787.mp4'\n",
    "# vname = 'test'\n",
    "\n",
    "# Preview\n",
    "vpath = getPreviewUrl(camera_name)\n",
    "vname = 'preview'\n",
    "\n",
    "## Replay\n",
    "# t1_str = '2021-3-25T08:00:00.000+08:00'\n",
    "# t2_str = '2021-3-25T09:00:00.000+08:00'\n",
    "# # ret = get_time_diff(t1_str, t2_str,camera_name)\n",
    "# # t1_str = ret['t1_str_new']\n",
    "# # t2_str = ret['t2_str_new']\n",
    "# vpath = getReplayUrl(camera_name, t1_str, t2_str)\n",
    "# vname = 'replay'\n",
    "\n",
    "dt= datetime.datetime.today()   \n",
    "dt_str = f'{dt:%m%d}'\n",
    "#folder = f'/mnt/hdd1/f45_output/{dt_str}'\n",
    "folder = f'/mnt/hdd1/f45_dev/FA_5L2_video/fail_image/{dt_str}'\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "assert os.path.exists(folder)\n",
    "\n",
    "# vpath = '/mnt/hdd1/f45_ipqc_issuelist/F45_5L2_2021-01-26T14:08:38.000+08:00_14.mp4'\n",
    "# idx = vpath.split('_')[-1]\n",
    "\n",
    "vidcap = cv2.VideoCapture(vpath)\n",
    "imagelist=[]\n",
    "success = True\n",
    "fid = 0\n",
    "bf_record = 0\n",
    "bk_record = 0\n",
    "t_record = datetime.datetime.now()\n",
    "save_image = None\n",
    "while success:\n",
    "    success, image = vidcap.read()\n",
    "    if image is None:\n",
    "        print('none image')\n",
    "        break\n",
    "    if fid > 108000:\n",
    "        break\n",
    "    image = image[:608,:720]\n",
    "    fid = fid + 1\n",
    "    fstart = time.time()\n",
    "    detections = yolo_dnn(image)\n",
    "    #print(fid, detections)\n",
    "    bat_img, f_score = yolo_bat(image, detections, 0.3)\n",
    "    if bat_img is not None:\n",
    "        results = mask_model.detect([bat_img], verbose=0)\n",
    "        r = results[0]\n",
    "        a = sorted(r['class_ids'].tolist())\n",
    "        if all(x in a for x in [1,2,3]) is False: #確認battery, black, vpen都在\n",
    "            continue\n",
    "        d= {}\n",
    "        for i in range(r['masks'].shape[2]):\n",
    "            cls_name = classid_mask[r['class_ids'][i]][0]\n",
    "            if cls_name in d.keys():\n",
    "                if d[cls_name][2] > r['scores'][i]:\n",
    "                    continue            \n",
    "            mask = r['masks'][:,:,i].astype(np.uint8)\n",
    "            mask*=255\n",
    "            cX, cY, area = mask_feature(mask)\n",
    "            if area == 0:\n",
    "                continue\n",
    "            d[classid_mask[r['class_ids'][i]][0]]=(cX, cY), area, r['scores'][i]\n",
    "        if ('vpen' and 'battery' and 'black' in d.keys()) is False:\n",
    "            continue\n",
    "        k_score = d['black'][1]\n",
    "        if k_score < 200: #black的限制\n",
    "            continue\n",
    "        if (datetime.datetime.now() - t_record).total_seconds() > 3.5: #是否同一\"次\"\n",
    "            now = datetime.datetime.now()\n",
    "            now_str = now.strftime('%Y-%m-%d-%H-%M-%S.%f')[:-5]        \n",
    "            jpg_path = os.path.join(folder, f'{now_str}.jpg')\n",
    "            if save_image is not None:\n",
    "                multiprocessing.Process(target = cv2.imwrite, args = (jpg_path, save_image)).start()\n",
    "            bf_record = 0\n",
    "            bk_record = 0\n",
    "        t_record = datetime.datetime.now()              \n",
    "        if (f_score - bf_record)*10 + (k_score - bk_record) <= 0: #是否要存該張frame\n",
    "            continue\n",
    "        bf_record = f_score\n",
    "        bk_record = k_score\n",
    "        end = time.time()\n",
    "        seconds = end - fstart   \n",
    "        fps = np.round(1 / seconds,2)\n",
    "        # draw image and output\n",
    "        mergeimg = draw_mask(bat_img, r['rois'], r['masks'], r['class_ids'], r['scores'])\n",
    "        image[:64,:128] = mergeimg\n",
    "        image = draw_bbox(image, detections)\n",
    "        image = draw_maskscore(image, r, d)\n",
    "        cv2.putText(image, f'FPS:{fps}', (10,530), cv2.FONT_HERSHEY_DUPLEX,0.7, (255,255,128), 1)\n",
    "        save_image = image\n",
    "#     end = time.time()\n",
    "#     seconds = end - fstart           \n",
    "#     fps = np.round(1 / seconds,2)\n",
    "#     if len(detections) >0:\n",
    "#         image = draw_bbox(image, detections)\n",
    "#     cv2.putText(image, f'FPS:{fps}', (10,530), cv2.FONT_HERSHEY_DUPLEX,0.7, (255,255,128), 1)\n",
    "    #imagelist.append(image)\n",
    "\n",
    "# folder = 'output'\n",
    "# writer = imageio.get_writer(str(idx), format='mp4', mode='I', fps=15)    \n",
    "# for img in imagelist:\n",
    "#     writer.append_data(img[:,:,::-1])\n",
    "# writer.close()\n",
    "# del imagelist\n",
    "# gc.collect()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cv2.getBuildInformation())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
