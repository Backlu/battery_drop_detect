{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import os, sys, joblib, glob, shutil, json, time, datetime\n",
    "import cv2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import pixellib\n",
    "from pixellib.custom_train import instance_custom_training\n",
    "from pixellib.instance import custom_segmentation\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import imageio\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import requests\n",
    "from sqlalchemy import Table, Column, String, Integer, MetaData, create_engine, insert, Text, DateTime, TIME\n",
    "import pymysql\n",
    "import threading, multiprocessing\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus)>0:\n",
    "    try:\n",
    "#         tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "#             [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2000)])\n",
    "#         logical_gpus = tf.config.experimental.list_logical_devices('GPU')        \n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print('No GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source of Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F45_5L2\n",
      "rtsp://10.142.81.21:554/openUrl/6xJAWBi\n"
     ]
    }
   ],
   "source": [
    "def getPreviewUrl(cameraName):\n",
    "    url = 'http://localhost:8081/v1/api/ipcamera/previewurl/name'\n",
    "#     url = 'http://10.142.3.61:8081/v1/api/ipcamera/previewurl/name'\n",
    "#    url = 'http://10.109.6.148:8081/v1/api/ipcamera/replayurl/name'     \n",
    "    data = {\n",
    "        \"cameraName\":cameraName,\n",
    "        \"expand\":\"streamform=rtp\" ,\n",
    "        #\"transcode=1&resolution=D1&bitrate=512&framerate=15&streamform=rtp&snapshot=1\"\n",
    "    }\n",
    "    data_json = json.dumps(data)\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "\n",
    "    response = requests.post(url, data=data_json, headers=headers)\n",
    "    jsonObject = response.json()\n",
    "    replayUrl = \"\"\n",
    "    if jsonObject['code'] == '200':\n",
    "        replayUrl = jsonObject['result']['replayUrl']\n",
    "    print(replayUrl)\n",
    "    return replayUrl\n",
    "\n",
    "\n",
    "def getReplayUrl(cameraName, t1_str, t2_str):\n",
    "    url = 'http://localhost:8081/v1/api/ipcamera/replayurl/name'\n",
    "    data = {\n",
    "        \"cameraName\":cameraName, \n",
    "        \"beginTime\":t1_str, \n",
    "        \"endTime\":t2_str,\n",
    "        \"expand\":\"streamform=rtp\",        \n",
    "#        \"expand\":\"transcode=1&resolution=D1&bitrate=1024&framerate=15&streamform=rtp\"\n",
    "    }\n",
    "    #print(f'{cameraName}: {t1_str} ~ {t2_str}')\n",
    "    data_json = json.dumps(data)\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "\n",
    "    response = requests.post(url, data=data_json, headers=headers)\n",
    "    jsonObject = response.json()\n",
    "    print(jsonObject)\n",
    "    replayUrl = \"\"\n",
    "    if jsonObject['code'] == '200':\n",
    "        replayUrl = jsonObject['result']['replayUrl']\n",
    "    print(replayUrl)\n",
    "    return replayUrl\n",
    "\n",
    "def checkImageNone(fid1, cameraName, cap):\n",
    "    print('last none fid:', fid1, datetime.datetime.today())\n",
    "    time.sleep(60)\n",
    "    replayUrl = getPreviewUrl(cameraName)\n",
    "    cap = cv2.VideoCapture(replayUrl)\n",
    "    ret, image = cap.read()\n",
    "    return ret, image\n",
    "\n",
    "def writeLog():\n",
    "    LOG_PATH = 'inference_log'\n",
    "    if not os.path.exists(LOG_PATH):\n",
    "        os.makedirs(LOG_PATH)\n",
    "\n",
    "    root = logging.getLogger()\n",
    "    level = logging.INFO\n",
    "    filename = LOG_PATH + '/' +  f'{datetime.datetime.now().strftime(\"%Y-%m-%d\")}.log'\n",
    "    format = '%(asctime)s Line:%(lineno)d %(message)s'\n",
    "    #filename, when to changefile, interval, backup count\n",
    "    hdlr = TimedRotatingFileHandler(filename, \"midnight\", 1, 14)\n",
    "    fmt = logging.Formatter(format)\n",
    "    hdlr.setFormatter(fmt)\n",
    "    root.addHandler(hdlr)\n",
    "    root.setLevel(level)\n",
    "    \n",
    "def detectHHMMSS(image, lang='snum'):\n",
    "    ret={'success':False, 'digit':None}\n",
    "    img_HHmmss = image[40:90, 305:515] if image.shape[:2] == (720,1280) else image[20:60,200:340]\n",
    "    #Get Green Color\n",
    "    img_HHmmss = cv2.cvtColor(img_HHmmss, cv2.COLOR_BGR2HSV)\n",
    "    lower_hsv = np.array([45,150,175])\n",
    "    upper_hsv = np.array([67,255,255])\n",
    "    img_mask = cv2.inRange(img_HHmmss, lower_hsv, upper_hsv)\n",
    "    digit = pytesseract.image_to_string(img_mask, lang=lang, config='--psm 7 digits')\n",
    "    if len(digit) ==8:\n",
    "        ret['success']=True\n",
    "        ret['digit']=digit\n",
    "    return ret\n",
    "\n",
    "def get_time_diff(t1_str, t2_str, MID):  #Note: 由於HIK的傳送機制(?)會有數秒的誤差\n",
    "    ret={}\n",
    "    ocr_pass=False\n",
    "    \n",
    "    #Replay\n",
    "    vpath = getReplayUrl(MID, t1_str, t2_str)\n",
    "    vidcap = cv2.VideoCapture(vpath)\n",
    "    \n",
    "    #OCR\n",
    "    for i in range(300):\n",
    "        success, image = vidcap.read()\n",
    "        ret = detectHHMMSS(image, lang='genius_preview')\n",
    "        if ret['success']==True:\n",
    "            print('OCR Pass')\n",
    "            ocr_pass=True\n",
    "            break\n",
    "        else:\n",
    "            print('OCR Fail')\n",
    "    #Check Diff\n",
    "    if ocr_pass:\n",
    "        digit= ret['digit']\n",
    "        hour=int(digit[:2])\n",
    "        minute = int(digit[3:5])\n",
    "        second =  int(digit[6:8])\n",
    "        dt_ocr = datetime.time(hour,minute, second)\n",
    "        t1_dt = datetime.datetime.strptime(t1_str, '%Y-%m-%dT%H:%M:%S.000+08:00')\n",
    "        t2_dt = datetime.datetime.strptime(t2_str, '%Y-%m-%dT%H:%M:%S.000+08:00')\n",
    "        today = datetime.datetime.today()\n",
    "        diff_seconds = (datetime.datetime.combine(today, t1_dt.time()) - datetime.datetime.combine(today, dt_ocr)).total_seconds()\n",
    "        t1_dt_new = t1_dt + datetime.timedelta(seconds=diff_seconds)\n",
    "        t2_dt_new = t2_dt + datetime.timedelta(seconds=diff_seconds)\n",
    "        t1_str_new = t1_dt_new.strftime('%Y-%m-%dT%H:%M:%S.000+08:00')\n",
    "        t2_str_new = t2_dt_new.strftime('%Y-%m-%dT%H:%M:%S.000+08:00')\n",
    "        ret['t1_str_new']=t1_str_new\n",
    "        ret['t2_str_new']=t2_str_new\n",
    "        ret['diff_seconds'] = diff_seconds\n",
    "    ret['success']=ocr_pass\n",
    "    return ret\n",
    "\n",
    "def checkFolderExist(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/hdd/IP_Camera_Installation/ipcamera-env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "test_video = custom_segmentation()\n",
    "test_video.inferConfig(num_classes= 9, class_names=[\"background\", \"battery_p1\", \"battery_f1\",'battery','vpen','wz','battery_p3','ppen','battery_p2','battery_f2'])\n",
    "test_video.load_model('model/f45_weight_final.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_debuginfo(image, fid, cls):\n",
    "    id_map = {x:classid_dict[x][0] for x in classid_dict.keys()}\n",
    "    fontsize=0.7\n",
    "    color=(255,255,128)\n",
    "    lspace=20\n",
    "    msg_w, msg_h = 5, 90\n",
    "    if cls is not None:\n",
    "        cv2.putText(image, f'cls:{[id_map[k] for k in cls.keys()]}', (10,130) , cv2.FONT_HERSHEY_DUPLEX , 0.4, color,1)\n",
    "        cv2.putText(image, f'score:{[int(v[0]*100) for v in cls.values()]}', (10,160) , cv2.FONT_HERSHEY_DUPLEX , fontsize, color,1)\n",
    "    return image     \n",
    "\n",
    "def draw_bbox(image, segmask):\n",
    "    for i in range(len(segmask['class_ids'])):\n",
    "        y1, x1, y2, x2 = segmask['rois'][i]\n",
    "        class_id = segmask['class_ids'][i]\n",
    "        label = classid_dict[class_id][0]\n",
    "        color = classid_dict[class_id][1]\n",
    "        score = segmask['scores'][i]\n",
    "        mask = segmask['masks'][:,:,i]\n",
    "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        if '_' not in label:\n",
    "            image = apply_mask(image, mask, color)\n",
    "    return image\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == 1,\n",
    "                                  image[:, :, c] * (1 - alpha) + alpha * color[c] * 1,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "\n",
    "def draw_fail(image, fps):\n",
    "    cv2.putText(image, 'Battery Fail', (10,300), cv2.FONT_HERSHEY_DUPLEX,1.5, (0,0,255), 1)\n",
    "    cv2.putText(image, f'FPS:{fps}', (10,530), cv2.FONT_HERSHEY_DUPLEX,0.7, (255,255,128), 1)\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_dist(loc1, loc2):\n",
    "    dist = np.sqrt( (loc1[0] - loc2[0])**2 + (loc1[1] - loc2[1])**2 )\n",
    "    return int(dist)\n",
    "\n",
    "def to_database(vid, error_time, error_type, jpg_link):\n",
    "    engine = create_engine('mysql+pymysql://root:123456@10.142.3.61:3306/ipcamera?charset=utf8mb4')\n",
    "    #conn = pymysql.connect (host='10.142.3.61', user='root', passwd='123456', db='ipcamera')\n",
    "    metadata = MetaData(bind=engine)\n",
    "    anomaly_info = Table('f45_anomaly_info', metadata,\n",
    "                         Column('vid', String(50), primary_key=True),   \n",
    "                         Column('error_time', String(50),  primary_key=True), \n",
    "                         Column('error_type', String(50)),\n",
    "                         Column('jpg_link', Text),\n",
    "                        )\n",
    "    metadata.create_all(engine)\n",
    "    conn = engine.connect()\n",
    "    act = insert(anomaly_info).values(vid=vid,\n",
    "                                      error_time = error_time,\n",
    "                                      error_type = error_type,\n",
    "                                      jpg_link = jpg_link\n",
    "                                     )\n",
    "    conn.execute(act)\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### API\n",
    "mid = 'F45_5L2'\n",
    "fps = 15\n",
    "camera_df = pd.read_excel(f'doc/camera_list_map.xlsx')\n",
    "camera_name = camera_df[camera_df['mid']==mid]['camera_name'].values[0]\n",
    "ip = camera_df[camera_df['mid']==mid]['ip'].values[0]\n",
    "line = camera_df[camera_df['mid']==mid]['mes_line'].values[0]\n",
    "station = camera_df[camera_df['mid']==mid]['mes_station'].values[0]\n",
    "print(mid) \n",
    "\n",
    "### Local files\n",
    "# vpath = '/mnt/hdd1/ipcamera_case_data/N01-3F_05L_F68-06_78.26_R11.12_202011181004_tape.mp4'\n",
    "# vname = vpath.split('/')[-1].split('_')[-2]\n",
    "# #vpath = 'output/1216/F68_5L2_replay_1608101363.1398787.mp4'\n",
    "# vname = 'test'\n",
    "\n",
    "## Preview\n",
    "vpath = getPreviewUrl(camera_name)\n",
    "vname = 'preview'\n",
    "\n",
    "## Replay\n",
    "# t1_str = '2021-3-11T06:47:25.000+08:00'\n",
    "# t2_str = '2021-3-11T06:48:40.000+08:00'\n",
    "# ret = get_time_diff(t1_str, t2_str,camera_name)\n",
    "# t1_str = ret['t1_str_new']\n",
    "# t2_str = ret['t2_str_new']\n",
    "# vpath = getReplayUrl(camera_name, t1_str, t2_str)\n",
    "# vname = 'replay'\n",
    "\n",
    "### RTSP\n",
    "# vpath = \"rtsp://admin:a1234567@\"+ ip +\"/h265/ch1/main/av_stream\"\n",
    "# vname = 'rtsp'\n",
    "\n",
    "dt= datetime.datetime.today()   \n",
    "dt_str = f'{dt:%m%d}'\n",
    "folder = f'/mnt/hdd1/f45_output/{dt_str}' \n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "assert os.path.exists(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Battery Fail at fid:931, 2021-03-23-15-18-53\n",
      "Battery Fail at fid:2002, 2021-03-23-15-20-04\n",
      "Battery Fail at fid:2965, 2021-03-23-15-21-08\n",
      "Battery Fail at fid:3946, 2021-03-23-15-22-14\n",
      "Battery Fail at fid:4918, 2021-03-23-15-23-18\n",
      "Battery Fail at fid:5824, 2021-03-23-15-24-19\n",
      "Battery Fail at fid:7000, 2021-03-23-15-25-37\n",
      "Battery Fail at fid:7096, 2021-03-23-15-25-44\n",
      "Battery Fail at fid:7960, 2021-03-23-15-26-41\n",
      "Battery Fail at fid:8866, 2021-03-23-15-27-42\n",
      "Battery Fail at fid:9910, 2021-03-23-15-28-51\n",
      "Battery Fail at fid:11191, 2021-03-23-15-30-17\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-42862b924d2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mfstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0msegmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_video\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegmentImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_bboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msegmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rois'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hdd/IP_Camera_Installation/ipcamera-env/lib/python3.6/site-packages/pixellib/instance.py\u001b[0m in \u001b[0;36msegmentImage\u001b[0;34m(self, image_path, show_bboxes, extract_segmented_objects, save_extracted_objects, mask_points_values, process_frame, output_image_name, verbose)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processing image...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_img\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hdd/IP_Camera_Installation/ipcamera-env/lib/python3.6/site-packages/pixellib/mask_rcnn.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, images, verbose)\u001b[0m\n\u001b[1;32m   2463\u001b[0m         \u001b[0;31m# Run object detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m         \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmrcnn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2465\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmolded_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2466\u001b[0m         \u001b[0;31m# Process detections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hdd/IP_Camera_Installation/ipcamera-env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hdd/IP_Camera_Installation/ipcamera-env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/mnt/hdd/IP_Camera_Installation/ipcamera-env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hdd/IP_Camera_Installation/ipcamera-env/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3566\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3567\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3568\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3569\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/mnt/hdd/IP_Camera_Installation/ipcamera-env/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1472\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1473\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classid_dict = {1:['battery_p1',(127,255,50)],\n",
    "              2:['battery_f1',(147,20,255)],\n",
    "              3:['battery',(135,138,128)],\n",
    "              4:['vpen',(153, 255,255)],\n",
    "              5:['wz',(221,160,221)],\n",
    "              6:['battery_p3',(127,255,50)],\n",
    "              7:['ppen',(255,255,86)],\n",
    "              8:['battery_p2',(127,255,50)],\n",
    "              9:['battery_f2',(147,20,255)]}\n",
    "\n",
    "vidcap = cv2.VideoCapture(vpath)\n",
    "imagelist=[]\n",
    "feature = {}\n",
    "success = True\n",
    "fid = 0\n",
    "vcenter1 = 566,332\n",
    "now = datetime.datetime.now()\n",
    "while success:\n",
    "    success, image = vidcap.read()\n",
    "    if image is None:\n",
    "        break\n",
    "    image = image[:608,:720]\n",
    "    fid = fid + 1\n",
    "    if fid % 3 != 1:\n",
    "        continue\n",
    "    fstart = time.time()\n",
    "    segmask, output = test_video.segmentImage(image, show_bboxes = True, process_frame = True)\n",
    "    cls = dict(zip(segmask['class_ids'], zip(segmask['scores'],segmask['rois'])))\n",
    "    \n",
    "    #確認 battery_f1(2) 和 battery_f2(9) 的分數\n",
    "    score = max(cls.get(2,(0,0))[0], cls.get(9,(0,0))[0])\n",
    "    segmask['status'] = 'F' if score > 0.8 else 'P'\n",
    "    \n",
    "    #確認 vpen的位置\n",
    "    a = cls.get(4,(0,[]))[1]\n",
    "    if len(a) >0:\n",
    "        y1, x1, y2, x2 = a\n",
    "        vcenter2 = (x1+x2)//2, (y1+y2)//2\n",
    "    else:\n",
    "        vcenter2 = (0,0)\n",
    "    vdist = get_dist(vcenter1, vcenter2) if vcenter2 != vcenter1 else 0\n",
    "    vcenter1 = vcenter2\n",
    "    if (fid>3) and (segmask['status'] is 'F') and (feature[fid-3]['status'] is 'F') and (vdist < 30) and ((datetime.datetime.now() - now).total_seconds()>5):\n",
    "        now = datetime.datetime.now()\n",
    "        now_str = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "        print(f'Battery Fail at fid:{fid}, {now_str}')\n",
    "        output = draw_fail(output, fps)\n",
    "        output = draw_bbox(output, segmask)\n",
    "        output = draw_debuginfo(output, fid, cls)\n",
    "        jpg_path = os.path.join(folder, f'{now_str}.jpg')\n",
    "        multiprocessing.Process(target = cv2.imwrite, args = (jpg_path, output)).start()         \n",
    "        multiprocessing.Process(target = to_database, args = (mid, now, 'battery_fail', jpg_path)).start() \n",
    "    del segmask['masks']\n",
    "    feature[fid] = segmask\n",
    "    end = time.time()\n",
    "    seconds = end - fstart   \n",
    "    fps = np.round(1 / seconds,2)\n",
    "    \n",
    "    if datetime.datetime.now().time() > datetime.time(23,59): #超過600秒就break\n",
    "        break\n",
    "\n",
    "gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
